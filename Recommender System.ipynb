{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For rank 10 the RMSE is 0.209641224328\n",
      "For rank 20 the RMSE is 0.190510570716\n",
      "The best model was trained with rank 20\n",
      "For testing data the RMSE is 1.36460648672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[((57385, 55150), (4.0, 3.4209773758940454)),\n",
       " ((369753, 4273), (5.0, 1.8178123602618355)),\n",
       " ((311359, 13138), (4.0, 4.330833858769683))]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "import json\n",
    "\n",
    "trainingRawData = sqlContext.read.json('../Datasets/Amazon/Baby/reviews_training_Baby_5.json')\n",
    "trainingData = trainingRawData.select(trainingRawData['reviewerID'],trainingRawData['asin'],trainingRawData['overall']).rdd\n",
    "\n",
    "overallRatingSum = trainingData.map(lambda l: l[2]).sum()\n",
    "\n",
    "mu = float(overallRatingSum/trainingData.count())\n",
    "\n",
    "testRawData = sqlContext.read.json('../Datasets/Amazon/Baby/reviews_test_Baby_5.json')\n",
    "testData = testRawData.select(testRawData['reviewerID'],testRawData['asin'],testRawData['overall']).rdd\n",
    "\n",
    "allData = trainingData.union(testData)\n",
    "orgReviewerIDs = allData.map(lambda l:l[0]).distinct()\n",
    "orgProductIDs = allData.map(lambda l:l[1]).distinct()\n",
    "\n",
    "ReviewerIDsMapping = dict(orgReviewerIDs.zipWithUniqueId().collect())\n",
    "ProductIDsMapping = dict(orgProductIDs.zipWithUniqueId().collect())\n",
    "\n",
    "training_RDD = trainingData.map(lambda l:(ReviewerIDsMapping[l[0]],ProductIDsMapping[l[1]], l[2]))\n",
    "validation_RDD = training_RDD.sample(False, 0.2, seed = 23).cache()\n",
    "test_RDD = testData.map(lambda l:(ReviewerIDsMapping[l[0]],ProductIDsMapping[l[1]], l[2])).cache()\n",
    "\n",
    "userRatingData = training_RDD.map(lambda l: (l[0],[l[2]])).reduceByKey(lambda x,y : x+y)\n",
    "userRatingData = userRatingData.map(lambda l: (l[0], sum(l[1])/len(l[1])))\n",
    "bu = dict(userRatingData.collect())\n",
    "\n",
    "productRatingData = training_RDD.map(lambda l: (l[1],[l[2]])).reduceByKey(lambda x,y : x+y)\n",
    "productRatingData = productRatingData.map(lambda l: (l[0], sum(l[1])/len(l[1])))\n",
    "bi = dict(productRatingData.collect())\n",
    "\n",
    "training_RDD = training_RDD.map(lambda l: (l[0], l[1], l[2]-mu -(bu[l[0]]-mu)-(bi[l[1]]-mu))).cache()\n",
    "\n",
    "validation_RDD_for_predict = validation_RDD.map(lambda row: (row[0],row[1]))\n",
    "test_RDD_for_predict = test_RDD.map(lambda row: (row[0],row[1]))\n",
    "\n",
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "seed = 5L\n",
    "iterations = 10\n",
    "regularization_parameter = 0.1\n",
    "ranks = [10, 20]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "tolerance = 0.02\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iterations,lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(validation_RDD_for_predict).map(lambda r: ((r[0], r[1]), r[2]+mu+(bu[r[0]]-mu)+(bi[r[1]]-mu)))\n",
    "    \n",
    "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print 'For rank %s the RMSE is %s' % (rank, error)\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print 'The best model was trained with rank %s' % best_rank\n",
    "\n",
    "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=regularization_parameter)\n",
    "predictions = model.predictAll(test_RDD_for_predict).map(lambda r: ((r[0], r[1]), r[2]+mu+(bu[r[0]]-mu)+(bi[r[1]]-mu)))\n",
    "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "\n",
    "print 'For testing data the RMSE is %s' % (error)\n",
    "\n",
    "rates_and_preds.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
